<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Bag of Words Model in NLP</title>
    <link href="/2023/09/04/Bag-of-Words-Model-in-NLP/"/>
    <url>/2023/09/04/Bag-of-Words-Model-in-NLP/</url>
    
    <content type="html"><![CDATA[<p>This article will introduce the common Bag of Words (BoW) model in NLP and how to utilize it for calculating the similarity between sentences using cosine similarity.</p><p>Firstly, let’s delve into what the Bag of Words model is. Let’s consider two simple sentences for example:</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">sent1</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;I love sky, I love sea.&quot;</span><br><span class="hljs-attribute">sent2</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;I like running, I love reading.&quot;</span><br></code></pre></td></tr></table></figure><p>In NLP, handling complete paragraphs or sentences at once is often challenging. Hence, the first step typically involves tokenization and word segmentation. Here, as we only have sentences, we’ll focus on tokenization. For English sentences, the <code>word_tokenize</code> function from NLTK can be used, while for Chinese sentences, the <code>jieba</code> module can be utilized. Therefore, the initial step is tokenization, with code as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize<br><br>sents = [sent1, sent2]<br>texts = [[word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word_tokenize(sent)] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents]<br></code></pre></td></tr></table></figure><p>The output result would be:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[[<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;sky&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;sea&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>], [<span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;like&#x27;</span>, <span class="hljs-string">&#x27;running&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;reading&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]]<br></code></pre></td></tr></table></figure><p>Tokenization is complete. The next step involves constructing a corpus, which consists of all words and punctuation appearing in the sentences. The code for creating the corpus is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">all_list = []<br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    all_list += text<br><br>corpus = <span class="hljs-built_in">set</span>(all_list)<br><span class="hljs-built_in">print</span>(corpus)<br></code></pre></td></tr></table></figure><p>The output would be a set containing all unique words and punctuation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;love&#x27;</span>, <span class="hljs-string">&#x27;running&#x27;</span>, <span class="hljs-string">&#x27;reading&#x27;</span>, <span class="hljs-string">&#x27;sky&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;like&#x27;</span>, <span class="hljs-string">&#x27;sea&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><p>The following step is to establish a numerical mapping for the words and punctuation in the corpus. This aids in the subsequent vector representation of sentences. The code for creating the mapping is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">corpus_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(corpus, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(corpus))))<br><span class="hljs-built_in">print</span>(corpus_dict)<br></code></pre></td></tr></table></figure><p>The output would be a dictionary mapping each unique word or punctuation to a numerical value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;<span class="hljs-string">&#x27;running&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;reading&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;love&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;sky&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;.&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;I&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;like&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;sea&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;,&#x27;</span>: <span class="hljs-number">8</span>&#125;<br></code></pre></td></tr></table></figure><p>Although the words and punctuation aren’t mapped based on their order of appearance, it won’t affect the vector representation of sentences and subsequent sentence similarity.</p><p>The next crucial step in the Bag of Words model is to establish vector representations for sentences. This representation doesn’t merely select 0s and 1s based on the presence of words or punctuation; instead, it considers the frequency of their appearance as their numerical representation. Combining the corpus dictionary previously created, the code for vector representation of sentences is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Establishing vector representation for sentences</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vector_rep</span>(<span class="hljs-params">text, corpus_dict</span>):<br>    vec = []<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> corpus_dict.keys():<br>        <span class="hljs-keyword">if</span> key <span class="hljs-keyword">in</span> text:<br>            vec.append((corpus_dict[key], text.count(key)))<br>        <span class="hljs-keyword">else</span>:<br>            vec.append((corpus_dict[key], <span class="hljs-number">0</span>))<br><br>    vec = <span class="hljs-built_in">sorted</span>(vec, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>])<br><br>    <span class="hljs-keyword">return</span> [item[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> vec]<br><br>vec1 = vector_rep(texts[<span class="hljs-number">0</span>], corpus_dict)<br>vec2 = vector_rep(texts[<span class="hljs-number">1</span>], corpus_dict)<br><span class="hljs-built_in">print</span>(vec1)<br><span class="hljs-built_in">print</span>(vec2)<br></code></pre></td></tr></table></figure><p>The output would represent the true vector representations of the sentences:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br>[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>Let’s pause for a moment and observe this vector. In the first sentence, “I” appears twice. In the corpus dictionary, “I” corresponds to the number 5, thus “5” appears twice in the first sentence, resulting in the tuple <code>(5, 2)</code> in the list, indicating that the word “I” appears twice in the first sentence. The true vector representations of the two sentences are:<br>[2, 0, 0, 1, 1, 2, 0, 1, 1]<br>[1, 1, 1, 0, 1, 2, 1, 0, 1]</p><p>Now, the Bag of Words model is complete. Next, we’ll utilize this model, specifically the vector representations of the two sentences, to calculate their similarity.</p><p>In NLP, when two sentences are represented as vectors, cosine similarity is often chosen as a measure of similarity. The cosine similarity of vectors is the cosine value of the angle between the vectors. The Python code for calculating cosine similarity is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">similarity_with_2_sents</span>(<span class="hljs-params">vec1, vec2</span>):<br>    inner_product = <span class="hljs-number">0</span><br>    square_length_vec1 = <span class="hljs-number">0</span><br>    square_length_vec2 = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> tup1, tup2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(vec1, vec2):<br>        inner_product += tup1 * tup2<br>        square_length_vec1 += tup1**<span class="hljs-number">2</span><br>        square_length_vec2 += tup2**<span class="hljs-number">2</span><br><br>    <span class="hljs-keyword">return</span> (inner_product / (sqrt(square_length_vec1 * square_length_vec2)))<br><br>cosine_sim = similarity_with_2_sents(vec1, vec2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;The cosine similarity between the two sentences is: %.4f.&#x27;</span> % cosine_sim)<br></code></pre></td></tr></table></figure><p>The output would be:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">The cosine similarity between the two sentences <span class="hljs-keyword">is</span>: <span class="hljs-number">0.7303</span>.<br></code></pre></td></tr></table></figure><p>Thus, we’ve obtained the similarity between sentences using the Bag of Words model.</p><p>However, in practical NLP projects, for computing sentence similarity, one can easily use the <code>gensim</code> module. Below is the code using <code>gensim</code> to calculate similarity between two sentences:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">sent1 = <span class="hljs-string">&quot;I love sky, I love sea.&quot;</span><br>sent2 = <span class="hljs-string">&quot;I like running, I love reading.&quot;</span><br><br><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize<br>sents = [sent1, sent2]<br>texts = [[word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word_tokenize(sent)] <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents]<br><br><span class="hljs-keyword">from</span> gensim <span class="hljs-keyword">import</span> corpora<br><span class="hljs-keyword">from</span> gensim.similarities <span class="hljs-keyword">import</span> Similarity<br><br><span class="hljs-comment"># Building the corpus</span><br>dictionary = corpora.Dictionary(texts)<br><br><span class="hljs-comment"># Using doc2bow as the Bag of Words model</span><br>corpus = [dictionary.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]<br>similarity = Similarity(<span class="hljs-string">&#x27;-Similarity-index&#x27;</span>, corpus, num_features=<span class="hljs-built_in">len</span>(dictionary))<br><br><span class="hljs-comment"># Obtaining the similarity between sentences</span><br>new_sentence = sent1<br>test_corpus_1 = dictionary.doc2bow(word_tokenize(new_sentence))<br><br>cosine_sim = similarity[test_corpus_1][<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Similarity between the two sentences using gensim: %.4f.&quot;</span> % cosine_sim)<br></code></pre></td></tr></table></figure><p>The output would be:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Similarity between the two sentences using gensim: <span class="hljs-number">0.7303</span>.<br></code></pre></td></tr></table></figure><p>Thank you for reading!</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Step-by-Step: Using Hexo and GitHub to Create Your Website</title>
    <link href="/2023/09/03/Step-by-Step-Using-Hexo-and-GitHub-to-Create-Your-Website/"/>
    <url>/2023/09/03/Step-by-Step-Using-Hexo-and-GitHub-to-Create-Your-Website/</url>
    
    <content type="html"><![CDATA[<p>Hi everyone! I’m excited to share that I’ve created my own website today! Welcome to my blog!</p><p>In this post, I’ll share my step-by-step approach to using Hexo and GitHub to build it. </p><h2 id="1-Preparation"><a href="#1-Preparation" class="headerlink" title="1. Preparation"></a>1. Preparation</h2><ol><li><p><strong>GitHub Account</strong></p><p>You’ll need a GitHub account. If you don’t have one, head over to the official website <a href="http://github.com/">http://github.com</a> to register.</p></li><li><p><strong>Install Git</strong></p><p>Install Git on your computer. I used homebrew for installation.</p></li><li><p><strong>Install Node.js</strong></p><p>Install Node.js on your computer. You can also use homebrew for this installation.</p></li></ol><h2 id="2-Create-Repository"><a href="#2-Create-Repository" class="headerlink" title="2. Create Repository"></a>2. Create Repository</h2><p>To set up your website:</p><ol><li><p><strong>Create Repository:</strong> Go to your GitHub account and navigate to “Your repositories” to access the repositories page. Create a new repository named <code>&lt;username&gt;.github.io</code>.</p></li><li><p><strong>Create Homepage File:</strong> Within this repository, create a new file named <code>index.html</code>. This file will serve as the homepage for your website.</p></li><li><p><strong>Add Content to Homepage:</strong> Populate the <code>index.html</code> file with some basic content. For instance:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>Hello<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>I&#x27;m xxx, and this is my personal website.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><p><strong>Commit Changes:</strong> After adding content, click “Commit new file” to save these changes to the repository.</p></li><li><p><strong>Access Your Homepage:</strong> Your newly created homepage’s address can be found in GitHub Pages at https:&#x2F;&#x2F;[your_username].github.io&#x2F;</p></li></ol><h2 id="3-Configure-SSH"><a href="#3-Configure-SSH" class="headerlink" title="3. Configure SSH"></a>3. Configure SSH</h2><p>To enable remote file uploads from your computer to your GitHub repository, configure SSH by following these steps:</p><ol><li>Click on your personal GitHub account’s “Settings” option.</li><li>Navigate to “SSH and GPG keys” to configure your SSH public key.</li></ol><h2 id="4-Blog-Initialization"><a href="#4-Blog-Initialization" class="headerlink" title="4. Blog Initialization"></a>4. Blog Initialization</h2><p>We’ll use Hexo to create your blog website. Hexo is a static blog site generator based on Node.js. You can find its official website at <a href="https://hexo.io/">https://hexo.io</a>.</p><p>Create an empty folder, for instance, <code>github_blog</code>. Use the <code>hexo init</code> command to initialize your blog. The contents of the initialized folder are described as follows:</p><ul><li><code>_config.yml</code>: Configuration information for the website, where you can set most parameters.</li><li><code>package.json</code>: Application information.</li><li><code>scaffolds</code>: Folder for templates. Hexo uses these to create files when you create a new post.</li><li><code>source</code>: Folder for resources.</li><li><code>themes</code>: Folder for themes, which Hexo uses to generate static pages.</li></ul><h2 id="5-Generating-Your-Personal-Blog-Website"><a href="#5-Generating-Your-Personal-Blog-Website" class="headerlink" title="5. Generating Your Personal Blog Website"></a>5. Generating Your Personal Blog Website</h2><p>Edit the <code>_config.yml</code> file with the following deployment information:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Deployment</span><br><span class="hljs-comment">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repo:</span> <span class="hljs-string">https://github.com/[your_username]/[your_repository_name]</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">main</span><br></code></pre></td></tr></table></figure><p>After installing the plugin <code>npm install hexo-deployer-git --save</code>, run the following commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean    <span class="hljs-comment"># Clean up data</span><br>hexo d -g    <span class="hljs-comment"># Generate the blog</span><br></code></pre></td></tr></table></figure><p>At this point, your blog data will be pushed to GitHub. The empty repository created in the first step will now have content. You can access your website at <a href="https://username.github.io/">https://username.github.io/</a>, where ‘username’ is your GitHub username.</p><h2 id="6-Create-a-New-Post"><a href="#6-Create-a-New-Post" class="headerlink" title="6. Create a New Post"></a>6. Create a New Post</h2><p>Let’s create a blog post titled “Hello world!” using the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new <span class="hljs-string">&quot;Hello world!&quot;</span><br></code></pre></td></tr></table></figure><p>This will generate a <code>Hello world!.md</code> file in the <code>source/_posts</code> folder within your current directory. The file will have the following content:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">---<br>title: Hello world!<br>date: 2023-09-02 18:32:29<br><span class="hljs-section">tags: [empty]</span><br><span class="hljs-section">---</span><br></code></pre></td></tr></table></figure><p>After the <code>---</code>, you can write the content of your blog post using Markdown format.</p><p>Once you’ve finished writing your blog post, use the following commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean    <span class="hljs-comment"># Clean up data</span><br>hexo d -g    <span class="hljs-comment"># Generate the blog</span><br></code></pre></td></tr></table></figure><p>This will update your personal blog with the newly added post.</p><p>I hope this guide helps you. Happy website building!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Website</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
